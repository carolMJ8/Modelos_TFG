{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 16:04:15.068231: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-19 16:04:15.123688: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-19 16:04:15.123723: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-19 16:04:15.125594: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-19 16:04:15.135579: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-19 16:04:16.326276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:root:TensorFlow Decision Forests 1.8.1 is compatible with the following TensorFlow Versions: ['2.15.0']. However, TensorFlow 2.15.1 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model, model_from_json\n",
    "from tensorflow.keras.models import load_model, save_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, Accuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import DataFunctions as data\n",
    "from tcn import tcn\n",
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo datos...\n",
      "2772069\n",
      "2772069\n",
      "500\n",
      "[[0.50053443 0.50016916 0.4985727  ... 0.55339297 0.52323788 0.50785172]\n",
      " [0.52055949 0.5641143  0.66144441 ... 0.77176262 0.77155477 0.80733289]\n",
      " [0.87316238 0.95551693 1.04186681 ... 1.03392188 0.92344196 0.73966601]]\n",
      "500\n",
      "[2 2 2 ... 5 5 5]\n",
      "Tamaño x_train -->  (3880, 500, 1)\n",
      "Tamaño y_train -->  (3880,)\n",
      "Tamaño x_test -->  (1664, 500, 1)\n",
      "Tamaño y_test -->  (1664,)\n",
      "[1 2 3 6]\n",
      "10\n",
      "10\n",
      "(500, 1)\n",
      "Input shape (500, 1)\n",
      "Capa input --> (None, 500, 1)\n",
      "Capa TCN ---> (None, 500, 32)\n",
      "Capa MaxPooling ---> (None, 250, 32)\n",
      "Capa de normalizacion ---> (None, 250, 32)\n",
      "Capa multi atención ---> (None, 250, 32)\n",
      "Capa de MHA --> (None, 250, 320)\n",
      "Capa de convolución --> (None, 250, 64)\n",
      "Capa de MaxPooling --> (None, 125, 64)\n",
      "Capa de GAPooling --> (None, 64)\n",
      "Capa de salida de la red --> (None, 8)\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 74s 140ms/step - loss: 0.1702 - accuracy: 0.9660\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 0.0303 - accuracy: 0.9912\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0300 - accuracy: 0.9923\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 0.0139 - accuracy: 0.9969\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0171 - accuracy: 0.9954\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0150 - accuracy: 0.9972\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 15s 127ms/step - loss: 0.0106 - accuracy: 0.9977\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 0.0187 - accuracy: 0.9946\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 0.0132 - accuracy: 0.9961\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 0.0268 - accuracy: 0.9918\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 0.0183 - accuracy: 0.9954\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 0.0095 - accuracy: 0.9974\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 0.0054 - accuracy: 0.9985\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 0.0047 - accuracy: 0.9985\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 16s 130ms/step - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0083 - accuracy: 0.9974\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0091 - accuracy: 0.9977\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 16s 130ms/step - loss: 0.0067 - accuracy: 0.9982\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0125 - accuracy: 0.9959\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 0.0063 - accuracy: 0.9977\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0032 - accuracy: 0.9985\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0021 - accuracy: 0.9992\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 0.0035 - accuracy: 0.9990\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0040 - accuracy: 0.9992\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 27/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 28/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 0.0066 - accuracy: 0.9974\n",
      "Epoch 29/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 0.0047 - accuracy: 0.9987\n",
      "Epoch 30/100\n",
      "122/122 [==============================] - 16s 130ms/step - loss: 0.0068 - accuracy: 0.9982\n",
      "Epoch 31/100\n",
      "122/122 [==============================] - 16s 130ms/step - loss: 0.0111 - accuracy: 0.9966\n",
      "Epoch 32/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0030 - accuracy: 0.9987\n",
      "Epoch 33/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0073 - accuracy: 0.9974\n",
      "Epoch 34/100\n",
      "122/122 [==============================] - 16s 128ms/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 35/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 5.2794e-04 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "122/122 [==============================] - 16s 130ms/step - loss: 2.8116e-04 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 1.6247e-04 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 39/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 7.9050e-04 - accuracy: 0.9997\n",
      "Epoch 40/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 1.5800e-04 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 0.0070 - accuracy: 0.9985\n",
      "Epoch 42/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0146 - accuracy: 0.9974\n",
      "Epoch 43/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 0.0199 - accuracy: 0.9954\n",
      "Epoch 44/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 0.0125 - accuracy: 0.9961\n",
      "Epoch 45/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0091 - accuracy: 0.9956\n",
      "Epoch 46/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0045 - accuracy: 0.9990\n",
      "Epoch 47/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0058 - accuracy: 0.9990\n",
      "Epoch 48/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 49/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 5.9341e-04 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 51/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 52/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.3261e-04 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 1.3192e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 9.0943e-05 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 4.5222e-05 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 1.6085e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 9.9148e-05 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 9.4856e-05 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 2.8037e-05 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 6.6084e-05 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 2.3641e-05 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "122/122 [==============================] - 16s 128ms/step - loss: 2.4059e-05 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 1.5433e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "122/122 [==============================] - 15s 127ms/step - loss: 3.9930e-05 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "122/122 [==============================] - 16s 128ms/step - loss: 1.4419e-05 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 7.0982e-05 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 3.1256e-05 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 1.6418e-05 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0025 - accuracy: 0.9987\n",
      "Epoch 70/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 0.0370 - accuracy: 0.9912\n",
      "Epoch 71/100\n",
      "122/122 [==============================] - 16s 130ms/step - loss: 0.0149 - accuracy: 0.9956\n",
      "Epoch 72/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 0.0112 - accuracy: 0.9972\n",
      "Epoch 73/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 0.0081 - accuracy: 0.9982\n",
      "Epoch 74/100\n",
      "122/122 [==============================] - 16s 128ms/step - loss: 0.0132 - accuracy: 0.9977\n",
      "Epoch 75/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 0.0099 - accuracy: 0.9974\n",
      "Epoch 76/100\n",
      "122/122 [==============================] - 15s 127ms/step - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 77/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 0.0051 - accuracy: 0.9987\n",
      "Epoch 78/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 0.0096 - accuracy: 0.9982\n",
      "Epoch 79/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 80/100\n",
      "122/122 [==============================] - 16s 130ms/step - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 81/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 82/100\n",
      "122/122 [==============================] - 16s 128ms/step - loss: 0.0049 - accuracy: 0.9982\n",
      "Epoch 83/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 0.0028 - accuracy: 0.9990\n",
      "Epoch 84/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 0.0082 - accuracy: 0.9982\n",
      "Epoch 85/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 0.0304 - accuracy: 0.9951\n",
      "Epoch 86/100\n",
      "122/122 [==============================] - 16s 128ms/step - loss: 0.0249 - accuracy: 0.9956\n",
      "Epoch 87/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 0.0119 - accuracy: 0.9966\n",
      "Epoch 88/100\n",
      "122/122 [==============================] - 16s 128ms/step - loss: 0.0038 - accuracy: 0.9985\n",
      "Epoch 89/100\n",
      "122/122 [==============================] - 16s 128ms/step - loss: 0.0018 - accuracy: 0.9990\n",
      "Epoch 90/100\n",
      "122/122 [==============================] - 16s 128ms/step - loss: 9.9854e-04 - accuracy: 0.9997\n",
      "Epoch 91/100\n",
      "122/122 [==============================] - 16s 127ms/step - loss: 7.6637e-04 - accuracy: 0.9997\n",
      "Epoch 92/100\n",
      "122/122 [==============================] - 16s 130ms/step - loss: 3.5643e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 94/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 2.3127e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "122/122 [==============================] - 16s 128ms/step - loss: 1.7796e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 1.2223e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "122/122 [==============================] - 15s 127ms/step - loss: 1.6108e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "122/122 [==============================] - 15s 127ms/step - loss: 3.3655e-05 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 7.7784e-05 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 7.7758e-05 - accuracy: 1.0000\n",
      "52/52 [==============================] - 6s 42ms/step - loss: 18.5412 - accuracy: 0.1605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[18.54119873046875, 0.16045673191547394]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   USER 1 BAG\n",
    "\n",
    "#Se obtienen los datos de los sensores normalizados y quitando los ceros. También se obtienen las etiquetas\n",
    "print(\"Obteniendo datos...\")\n",
    "data_070717_bag, labels_070717_bag = data.get_data('Data10Tensors/User3/User3_10tensors_070717_bag.csv', '../User3/070717/Label_New_User3_070717.txt')\n",
    "\n",
    "print(len(data_070717_bag))\n",
    "print(len(labels_070717_bag))\n",
    "\n",
    "# Del dataset de datos se tienen que sacar 10 arrays numpy, uno por columna\n",
    "df_arrays_070717_bag, dict_arrays_070717_bag = data.get_arrays_from_data(data_070717_bag, labels_070717_bag)\n",
    "# Dividimos cada array en ventanas\n",
    "windows_dict_070717_bag, windows_labels_070717_bag = data.divide_data_arrays_into_windows(df_arrays_070717_bag, labels_070717_bag, True, 500)\n",
    "print(len(windows_dict_070717_bag['AcelX'][0]))\n",
    "print(windows_dict_070717_bag['AcelX'][:3])\n",
    "print(len(windows_dict_070717_bag['AcelX'][0]))\n",
    "print(windows_labels_070717_bag[:-11])\n",
    "\n",
    "# Dividimos los conjuntos de ventanas en los subconjuntos de entrenamiento y pruebas\n",
    "x_train_070717_bag, y_train_070717_bag, x_test_070717_bag, y_test_070717_bag = data.divide_train_test(windows_dict_070717_bag, windows_labels_070717_bag, 0.7)\n",
    "print(\"Tamaño x_train --> \", x_train_070717_bag['AcelX'].shape)\n",
    "print(\"Tamaño y_train --> \", y_train_070717_bag.shape)\n",
    "print(\"Tamaño x_test --> \", x_test_070717_bag['AcelX'].shape)\n",
    "print(\"Tamaño y_test --> \", y_test_070717_bag.shape)\n",
    "print(np.unique(np.array(y_train_070717_bag)))\n",
    "\n",
    "input_tensors_070717_bag = [tf.constant(x_train_070717_bag['AcelX']), tf.constant(x_train_070717_bag['AcelY']), tf.constant(x_train_070717_bag['AcelZ']), tf.constant(x_train_070717_bag['MagX']), tf.constant(x_train_070717_bag['MagY']), tf.constant(x_train_070717_bag['MagZ']), tf.constant(x_train_070717_bag['GirosX']), tf.constant(x_train_070717_bag['GirosY']), tf.constant(x_train_070717_bag['GirosZ']), tf.constant(x_train_070717_bag['Pres'])]\n",
    "print(len(input_tensors_070717_bag))\n",
    "input_tensors_test_070717_bag = [tf.constant(x_test_070717_bag['AcelX']), tf.constant(x_test_070717_bag['AcelY']), tf.constant(x_test_070717_bag['AcelZ']), tf.constant(x_test_070717_bag['MagX']), tf.constant(x_test_070717_bag['MagY']), tf.constant(x_test_070717_bag['MagZ']), tf.constant(x_test_070717_bag['GirosX']), tf.constant(x_test_070717_bag['GirosY']), tf.constant(x_test_070717_bag['GirosZ']), tf.constant(x_test_070717_bag['Pres'])]\n",
    "print(len(input_tensors_test_070717_bag))\n",
    "\n",
    "input_shape_070717_bag = x_train_070717_bag['AcelX'].shape[1:]\n",
    "print(input_shape_070717_bag)\n",
    "model_070717_bag = data.create_model(input_shape_070717_bag)\n",
    "\n",
    "model_070717_bag.fit(input_tensors_070717_bag, tf.cast(tf.constant(y_train_070717_bag), tf.float32), epochs=100)\n",
    "\n",
    "model_070717_bag.evaluate(x=input_tensors_test_070717_bag, y=y_test_070717_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model_070717_bag.to_json()\n",
    "with open('ModelsMemo/User3/user3_070717_bag/model.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model_070717_bag.save_weights('ModelsMemo/User3/user3_070717_bag/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   USER 1 hand\n",
    "\n",
    "#Se obtienen los datos de los sensores normalizados y quitando los ceros. También se obtienen las etiquetas\n",
    "print(\"Obteniendo datos...\")\n",
    "data_070717_hand, labels_070717_hand = data.get_data('Data10Tensors/User3/User3_10tensors_070717_hand.csv', '../User3/070717/Label_New_User3_070717_v2.txt')\n",
    "\n",
    "print(len(data_070717_hand))\n",
    "print(len(labels_070717_hand))\n",
    "\n",
    "# Del dataset de datos se tienen que sacar 10 arrays numpy, uno por columna\n",
    "df_arrays_070717_hand, dict_arrays_070717_hand = data.get_arrays_from_data(data_070717_hand, labels_070717_hand)\n",
    "# Dividimos cada array en ventanas\n",
    "windows_dict_070717_hand, windows_labels_070717_hand = data.divide_data_arrays_into_windows(df_arrays_070717_hand, labels_070717_hand, True, 500)\n",
    "print(len(windows_dict_070717_hand['AcelX'][0]))\n",
    "print(windows_dict_070717_hand['AcelX'][:3])\n",
    "print(len(windows_dict_070717_hand['AcelX'][0]))\n",
    "print(windows_labels_070717_hand[:-11])\n",
    "\n",
    "# Dividimos los conjuntos de ventanas en los subconjuntos de entrenamiento y pruebas\n",
    "x_train_070717_hand, y_train_070717_hand, x_test_070717_hand, y_test_070717_hand = data.divide_train_test(windows_dict_070717_hand, windows_labels_070717_hand, 0.7)\n",
    "print(\"Tamaño x_train --> \", x_train_070717_hand['AcelX'].shape)\n",
    "print(\"Tamaño y_train --> \", y_train_070717_hand.shape)\n",
    "print(\"Tamaño x_test --> \", x_test_070717_hand['AcelX'].shape)\n",
    "print(\"Tamaño y_test --> \", y_test_070717_hand.shape)\n",
    "print(np.unique(np.array(y_train_070717_hand)))\n",
    "\n",
    "input_tensors_070717_hand = [tf.constant(x_train_070717_hand['AcelX']), tf.constant(x_train_070717_hand['AcelY']), tf.constant(x_train_070717_hand['AcelZ']), tf.constant(x_train_070717_hand['MagX']), tf.constant(x_train_070717_hand['MagY']), tf.constant(x_train_070717_hand['MagZ']), tf.constant(x_train_070717_hand['GirosX']), tf.constant(x_train_070717_hand['GirosY']), tf.constant(x_train_070717_hand['GirosZ']), tf.constant(x_train_070717_hand['Pres'])]\n",
    "print(len(input_tensors_070717_hand))\n",
    "input_tensors_test_070717_hand = [tf.constant(x_test_070717_hand['AcelX']), tf.constant(x_test_070717_hand['AcelY']), tf.constant(x_test_070717_hand['AcelZ']), tf.constant(x_test_070717_hand['MagX']), tf.constant(x_test_070717_hand['MagY']), tf.constant(x_test_070717_hand['MagZ']), tf.constant(x_test_070717_hand['GirosX']), tf.constant(x_test_070717_hand['GirosY']), tf.constant(x_test_070717_hand['GirosZ']), tf.constant(x_test_070717_hand['Pres'])]\n",
    "print(len(input_tensors_test_070717_hand))\n",
    "\n",
    "input_shape_070717_hand = x_train_070717_hand['AcelX'].shape[1:]\n",
    "print(input_shape_070717_hand)\n",
    "model_070717_hand = data.create_model(input_shape_070717_hand)\n",
    "\n",
    "model_070717_hand.fit(input_tensors_070717_hand, tf.cast(tf.constant(y_train_070717_hand), tf.float32), epochs=100)\n",
    "\n",
    "model_070717_hand.evaluate(x=input_tensors_test_070717_hand, y=y_test_070717_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model_070717_hand.to_json()\n",
    "with open('ModelsMemo/User3/user3_070717_hand/model.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model_070717_hand.save_weights('ModelsMemo/User3/user3_070717_hand/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   USER 1 HIPS\n",
    "\n",
    "#Se obtienen los datos de los sensores normalizados y quitando los ceros. También se obtienen las etiquetas\n",
    "print(\"Obteniendo datos...\")\n",
    "data_070717_hips, labels_070717_hips = data.get_data('Data10Tensors/User3/User3_10tensors_070717_hips.csv', '../User3/070717/Label_New_User3_070717.txt')\n",
    "\n",
    "print(len(data_070717_hips))\n",
    "print(len(labels_070717_hips))\n",
    "\n",
    "# Del dataset de datos se tienen que sacar 10 arrays numpy, uno por columna\n",
    "df_arrays_070717_hips, dict_arrays_070717_hips = data.get_arrays_from_data(data_070717_hips, labels_070717_hips)\n",
    "# Dividimos cada array en ventanas\n",
    "windows_dict_070717_hips, windows_labels_070717_hips = data.divide_data_arrays_into_windows(df_arrays_070717_hips, labels_070717_hips, True, 500)\n",
    "print(len(windows_dict_070717_hips['AcelX'][0]))\n",
    "print(windows_dict_070717_hips['AcelX'][:3])\n",
    "print(len(windows_dict_070717_hips['AcelX'][0]))\n",
    "print(windows_labels_070717_hips[:-11])\n",
    "\n",
    "# Dividimos los conjuntos de ventanas en los subconjuntos de entrenamiento y pruebas\n",
    "x_train_070717_hips, y_train_070717_hips, x_test_070717_hips, y_test_070717_hips = data.divide_train_test(windows_dict_070717_hips, windows_labels_070717_hips, 0.7)\n",
    "print(\"Tamaño x_train --> \", x_train_070717_hips['AcelX'].shape)\n",
    "print(\"Tamaño y_train --> \", y_train_070717_hips.shape)\n",
    "print(\"Tamaño x_test --> \", x_test_070717_hips['AcelX'].shape)\n",
    "print(\"Tamaño y_test --> \", y_test_070717_hips.shape)\n",
    "print(np.unique(np.array(y_train_070717_hips)))\n",
    "\n",
    "input_tensors_070717_hips = [tf.constant(x_train_070717_hips['AcelX']), tf.constant(x_train_070717_hips['AcelY']), tf.constant(x_train_070717_hips['AcelZ']), tf.constant(x_train_070717_hips['MagX']), tf.constant(x_train_070717_hips['MagY']), tf.constant(x_train_070717_hips['MagZ']), tf.constant(x_train_070717_hips['GirosX']), tf.constant(x_train_070717_hips['GirosY']), tf.constant(x_train_070717_hips['GirosZ']), tf.constant(x_train_070717_hips['Pres'])]\n",
    "print(len(input_tensors_070717_hips))\n",
    "input_tensors_test_070717_hips = [tf.constant(x_test_070717_hips['AcelX']), tf.constant(x_test_070717_hips['AcelY']), tf.constant(x_test_070717_hips['AcelZ']), tf.constant(x_test_070717_hips['MagX']), tf.constant(x_test_070717_hips['MagY']), tf.constant(x_test_070717_hips['MagZ']), tf.constant(x_test_070717_hips['GirosX']), tf.constant(x_test_070717_hips['GirosY']), tf.constant(x_test_070717_hips['GirosZ']), tf.constant(x_test_070717_hips['Pres'])]\n",
    "print(len(input_tensors_test_070717_hips))\n",
    "\n",
    "input_shape_070717_hips = x_train_070717_hips['AcelX'].shape[1:]\n",
    "print(input_shape_070717_hips)\n",
    "model_070717_hips = data.create_model(input_shape_070717_hips)\n",
    "\n",
    "model_070717_hips.fit(input_tensors_070717_hips, tf.cast(tf.constant(y_train_070717_hips), tf.float32), epochs=100)\n",
    "\n",
    "model_070717_hips.evaluate(x=input_tensors_test_070717_hips, y=y_test_070717_hips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model_070717_hips.to_json()\n",
    "with open('ModelsMemo/User3/user3_070717_hips/model.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model_070717_hips.save_weights('ModelsMemo/User3/user3_070717_hips/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
