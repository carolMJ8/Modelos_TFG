{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 09:20:21.579368: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-11 09:20:21.612177: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-11 09:20:21.612198: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-11 09:20:21.613193: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-11 09:20:21.618928: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-11 09:20:22.298194: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import SlidingWindows as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo datos...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hecho!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Se obtienen los datos de los sensores y las etiquetas deducidas\n",
    "print(\"Obteniendo datos...\")\n",
    "data_2206_17_bag, tags_220617_bag = data.get_data('/home/cmonedero/TFG/User1/Motion/User1_220617_Bag.csv', '/home/cmonedero/TFG/User1/220617/Label_New_User1_220617.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividiendo en ventanas el dataset...\n",
      "Hecho!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Se divide el dataset en ventanas de tamaño 500\n",
    "print(\"Dividiendo en ventanas el dataset...\")\n",
    "x_windows_220617_bag, y_windows_220617_bag = data.divide_data_arrays_into_windows(data_2206_17_bag, tags_220617_bag, window_size=500, moda=True)\n",
    "# print(\"Tamaño ventanas X --> \", x_windows_220617_bag.shape)\n",
    "# print(\"Tamaño ventanas Y --> \", y_windows_220617_bag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividiendo en train y test...\n",
      "Hecho!\n",
      "\n",
      "Tamaño x_train -->  (2920, 500, 6)\n",
      "Tamaño y_train --> (2920,)\n",
      "Tamaño x_test -->  (731, 500, 6)\n",
      "Tamaño y_test --> (731,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dividiendo en train y test...\")\n",
    "x_train_220617_bag, y_train_220617_bag, x_test_220617_bag, y_test_220617_bag = data.divide_train_test(x_windows_220617_bag, y_windows_220617_bag, 0.8)\n",
    "print(\"Tamaño x_train --> \", x_train_220617_bag.shape)\n",
    "print(\"Tamaño y_train -->\", y_train_220617_bag.shape)\n",
    "print(\"Tamaño x_test --> \", x_test_220617_bag.shape)\n",
    "print(\"Tamaño y_test -->\", y_test_220617_bag.shape)\n",
    "\n",
    "# x_tf_220617_bag = tf.data.Dataset.from_tensor_slices((tf.constant(x_train_220617_bag), tf.cast(tf.constant(y_train_220617_bag), tf.float32)))\n",
    "# BATCH_SIZE=32\n",
    "# x_tf_train_220617_bag = x_tf_220617_bag.cache().batch(BATCH_SIZE)\n",
    "# print(type(x_tf_train_220617_bag))\n",
    "# print(x_tf_train_220617_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 6)\n",
      "Creando el modelo...\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 15:54:57.364624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 970 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:31:00.0, compute capability: 8.6\n",
      "2024-05-15 15:54:57.367026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 40933 MB memory:  -> device: 1, name: NVIDIA A40, pci bus id: 0000:98:00.0, compute capability: 8.6\n",
      "2024-05-15 15:54:57.531118: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 8)                 480       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 72        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 552 (2.16 KB)\n",
      "Trainable params: 552 (2.16 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#SOLO EJECUTAR ESTA CELDA SI SE QUIERE VOLVER A ENTRENAR EL MODELO O SE ENTRENA POR PRIMERA VEZ!!!\n",
    "input_shape = x_train_220617_bag.shape[1:]\n",
    "print(input_shape)\n",
    "print(\"Creando el modelo...\")\n",
    "model_220617_bag = data.create_model(input_shape)\n",
    "print(model_220617_bag.summary())\n",
    "cp_220617_bag = ModelCheckpoint('/home/cmonedero/TFG/MHA/checkpoint.model.keras', save_best_only=True)\n",
    "#print(x_tf_train_220617_bag)\n",
    "# data.train_model(model_220617_bag, cp_220617_bag, x_tf_train_220617_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando el modelo...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 15:55:11.132474: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f7879f5bee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-15 15:55:11.132521: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6\n",
      "2024-05-15 15:55:11.132529: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA A40, Compute Capability 8.6\n",
      "2024-05-15 15:55:11.144375: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-15 15:55:11.203561: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715788511.327536  973820 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - ETA: 0s - loss: 1.8354 - accuracy: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "92/92 [==============================] - 58s 593ms/step - loss: 1.8354 - accuracy: 0.0606\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - ETA: 0s - loss: 1.6463 - accuracy: 0.4942WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "92/92 [==============================] - 55s 593ms/step - loss: 1.6463 - accuracy: 0.4942\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - ETA: 0s - loss: 1.5095 - accuracy: 0.5366WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "92/92 [==============================] - 54s 589ms/step - loss: 1.5095 - accuracy: 0.5366\n",
      "Epoch 4/10\n",
      "92/92 [==============================] - ETA: 0s - loss: 1.4108 - accuracy: 0.5366WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "92/92 [==============================] - 54s 590ms/step - loss: 1.4108 - accuracy: 0.5366\n",
      "Epoch 5/10\n",
      "92/92 [==============================] - ETA: 0s - loss: 1.3393 - accuracy: 0.5366WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "92/92 [==============================] - 55s 598ms/step - loss: 1.3393 - accuracy: 0.5366\n",
      "Epoch 6/10\n",
      "92/92 [==============================] - ETA: 0s - loss: 1.2862 - accuracy: 0.5366WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "92/92 [==============================] - 55s 595ms/step - loss: 1.2862 - accuracy: 0.5366\n",
      "Epoch 7/10\n",
      "92/92 [==============================] - ETA: 0s - loss: 1.2459 - accuracy: 0.5366WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "92/92 [==============================] - 55s 596ms/step - loss: 1.2459 - accuracy: 0.5366\n",
      "Epoch 8/10\n",
      "92/92 [==============================] - ETA: 0s - loss: 1.2158 - accuracy: 0.5366WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "92/92 [==============================] - 55s 593ms/step - loss: 1.2158 - accuracy: 0.5366\n",
      "Epoch 9/10\n",
      "92/92 [==============================] - ETA: 0s - loss: 1.1931 - accuracy: 0.5366WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "92/92 [==============================] - 54s 590ms/step - loss: 1.1931 - accuracy: 0.5366\n",
      "Epoch 10/10\n",
      "92/92 [==============================] - ETA: 0s - loss: 1.1751 - accuracy: 0.5366WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "92/92 [==============================] - 54s 589ms/step - loss: 1.1751 - accuracy: 0.5366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7dcd9c9d80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Entrenando el modelo...\")\n",
    "model_220617_bag.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "model_220617_bag.fit(tf.constant(x_train_220617_bag), tf.cast(tf.constant(y_train_220617_bag), tf.float32), epochs=10, callbacks=[cp_220617_bag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 3s 118ms/step - loss: 1.7927 - accuracy: 0.5732\n"
     ]
    }
   ],
   "source": [
    "evals = model_220617_bag.evaluate(tf.constant(x_test_220617_bag), tf.cast(tf.constant(y_test_220617_bag), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_220617_bag.save('LSTMMemo/lstm.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
