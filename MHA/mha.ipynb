{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 09:31:59.310489: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-11 09:31:59.343474: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-11 09:31:59.343494: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-11 09:31:59.344449: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-11 09:31:59.350105: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-11 09:32:00.003855: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import DataFunctions as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo datos...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hecho!\n",
      "\n",
      "1825611\n",
      "1825611\n"
     ]
    }
   ],
   "source": [
    "#Se obtienen los datos de los sensores y las etiquetas deducidas\n",
    "print(\"Obteniendo datos...\")\n",
    "data_2206_17_bag, tags_220617_bag = data.get_data('/home/cmonedero/TFG/User1/Motion/User1_220617_Bag.csv', '/home/cmonedero/TFG/User1/220617/Label_New_User1_220617.txt')\n",
    "print(len(data_2206_17_bag))\n",
    "print(len(tags_220617_bag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.07019924  1.63547533 -0.49684637  0.02752316  0.02210398  1.90782759]\n",
      " [ 1.50750962  1.216529   -0.47890487  0.02751279  0.02248623  1.67817769]\n",
      " [ 1.66881362  1.40994663 -0.46373208  0.02751719  0.0222481   2.34294079]\n",
      " ...\n",
      " [-0.04260902 -0.17239478 -0.67691574  0.02764215  0.02275917 -0.24600538]\n",
      " [-0.05522627 -0.16790638 -0.67455615  0.02763254  0.02263291 -0.18964522]\n",
      " [-0.22125715 -0.17316984 -0.66096158  0.02762491  0.02281223 -0.21663067]]\n"
     ]
    }
   ],
   "source": [
    "print(data_2206_17_bag[['Módulo Acelerómetro', 'Módulo Giroscopio', 'Módulo Magnetómetro', 'Módulo Orientación', 'Módulo Gravedad', 'Módulo Acel. Lineal']].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividiendo en ventanas el dataset...\n",
      "Hecho!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Dividiendo en ventanas el dataset...\")\n",
    "x_windows_220617_bag, y_windows_220617_bag = data.divide_data_arrays_into_windows(data_2206_17_bag, tags_220617_bag, moda=False, window_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño ventanas X -->  (3651, 500, 6)\n",
      "Tamaño ventanas Y -->  (3651, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño ventanas X --> \", x_windows_220617_bag.shape)\n",
    "print(\"Tamaño ventanas Y --> \", y_windows_220617_bag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividiendo en train y test...\n",
      "Tamaño x_train -->  (2555, 500, 6)\n",
      "Tamaño y_train -->  (2555, 1)\n",
      "Tamaño x_test -->  (1096, 500, 6)\n",
      "Tamaño y_test --> (1096, 1)\n"
     ]
    }
   ],
   "source": [
    "#Se divide el dataset en los subconjuntos de train y test\n",
    "print(\"Dividiendo en train y test...\")\n",
    "x_train_220617_bag, y_train_220617_bag, x_test_220617_bag, y_test_220617_bag = data.divide_train_test(x_windows_220617_bag, y_windows_220617_bag, 0.7)\n",
    "print(\"Tamaño x_train --> \", x_train_220617_bag.shape)\n",
    "print(\"Tamaño y_train --> \", y_train_220617_bag.shape)\n",
    "print(\"Tamaño x_test --> \", x_test_220617_bag.shape)\n",
    "print(\"Tamaño y_test -->\", y_test_220617_bag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 6)\n",
      "(2555, 500, 6)\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train_220617_bag.shape[1:]\n",
    "print(input_shape)\n",
    "print(x_train_220617_bag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiheadattention(inputs, head_size, num_heads, ff_dim, dropout=0, i=0):\n",
    "\n",
    "    # print(\"Bloque número \", i, \" --> inputs shape \", inputs)\n",
    "    x = BatchNormalization(epsilon=1e-6)(inputs)\n",
    "    # print(\"Después de la normalización por batches ---> \", x)\n",
    "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout )(x, x)\n",
    "    # print(\"Después de la capa multi atención --> \", x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    # print(\"Después del dropout --> \", x)\n",
    "    res = x + inputs\n",
    "    # print(\"Bloque residual --> \", res)\n",
    "\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, head_size, num_heads, ff_dim, num_blocks, mlp_units, dropout=0, mlp_dropout=0):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    i = 0\n",
    "    for _ in range(num_blocks):\n",
    "        x = multiheadattention(x, head_size, num_heads, ff_dim, dropout, i)\n",
    "        i += 1\n",
    "    # print(\"\\n\\n\")\n",
    "    print(\"Después de las capas de atención --> \", x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    print(\"Despues del global average pooling --> \", x)\n",
    "    # x = Dense(input_shape[1], activation='relu')(x) \n",
    "    print(\"Despues de la capa FC --> \", x)\n",
    "    # x = Dropout(mlp_dropout)(x)\n",
    "    print(\"Despues del dropout --> \", x)\n",
    "    outputs = Dense(8, 'softmax')(x)\n",
    "    print(\"\\n\\nSalida --> \", outputs)\n",
    "    \n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 16:29:30.378858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 41198 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:31:00.0, compute capability: 8.6\n",
      "2024-05-15 16:29:30.381108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 41198 MB memory:  -> device: 1, name: NVIDIA A40, pci bus id: 0000:98:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de las capas de atención -->  KerasTensor(type_spec=TensorSpec(shape=(None, 500, 6), dtype=tf.float32, name=None), name='tf.__operators__.add_9/AddV2:0', description=\"created by layer 'tf.__operators__.add_9'\")\n",
      "Despues del global average pooling -->  KerasTensor(type_spec=TensorSpec(shape=(None, 6), dtype=tf.float32, name=None), name='global_average_pooling1d/Mean:0', description=\"created by layer 'global_average_pooling1d'\")\n",
      "Despues de la capa FC -->  KerasTensor(type_spec=TensorSpec(shape=(None, 6), dtype=tf.float32, name=None), name='global_average_pooling1d/Mean:0', description=\"created by layer 'global_average_pooling1d'\")\n",
      "Despues del dropout -->  KerasTensor(type_spec=TensorSpec(shape=(None, 6), dtype=tf.float32, name=None), name='global_average_pooling1d/Mean:0', description=\"created by layer 'global_average_pooling1d'\")\n",
      "\n",
      "\n",
      "Salida -->  KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name=None), name='dense/Softmax:0', description=\"created by layer 'dense'\")\n",
      "Entrenando el modelo...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 16:29:34.261151: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-05-15 16:29:35.647745: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fd77afd4850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-15 16:29:35.647782: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6\n",
      "2024-05-15 16:29:35.647788: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA A40, Compute Capability 8.6\n",
      "2024-05-15 16:29:35.655605: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-15 16:29:35.702273: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715790575.831357  984951 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 15s 99ms/step - loss: 1.2881 - accuracy: 0.5629 - val_loss: 0.3702 - val_accuracy: 0.9375\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 6s 90ms/step - loss: 0.6497 - accuracy: 0.7864 - val_loss: 0.3948 - val_accuracy: 0.8594\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 7s 92ms/step - loss: 0.4798 - accuracy: 0.8556 - val_loss: 0.2964 - val_accuracy: 0.9258\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 7s 91ms/step - loss: 0.4066 - accuracy: 0.8512 - val_loss: 0.2864 - val_accuracy: 0.9219\n",
      "Epoch 5/10\n",
      "72/72 [==============================] - 7s 92ms/step - loss: 0.3473 - accuracy: 0.8765 - val_loss: 0.1767 - val_accuracy: 0.9570\n",
      "Epoch 6/10\n",
      "72/72 [==============================] - 6s 89ms/step - loss: 0.3077 - accuracy: 0.8952 - val_loss: 0.2655 - val_accuracy: 0.9375\n",
      "Epoch 7/10\n",
      "72/72 [==============================] - 7s 92ms/step - loss: 0.2685 - accuracy: 0.8943 - val_loss: 0.1405 - val_accuracy: 0.9648\n",
      "Epoch 8/10\n",
      "72/72 [==============================] - 6s 89ms/step - loss: 0.2732 - accuracy: 0.8943 - val_loss: 0.1578 - val_accuracy: 0.9609\n",
      "Epoch 9/10\n",
      "72/72 [==============================] - 6s 89ms/step - loss: 0.2642 - accuracy: 0.8904 - val_loss: 0.2066 - val_accuracy: 0.9531\n",
      "Epoch 10/10\n",
      "72/72 [==============================] - 6s 89ms/step - loss: 0.2424 - accuracy: 0.9008 - val_loss: 0.1424 - val_accuracy: 0.9648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fe9ed820eb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = x_train_220617_bag.shape[1:]\n",
    "model_220617_bag = build_model(input_shape, head_size=4, num_heads=8, ff_dim=4, mlp_units=[5], num_blocks=5, mlp_dropout=0.4, dropout=0.25)\n",
    "checkpoint_filepath = '/home/cmonedero/TFG/MHA/checkpoint.model.keras'\n",
    "cp_220617_bag = ModelCheckpoint(filepath=checkpoint_filepath, save_best_only=True, save_freq='epoch')\n",
    "\n",
    "print(\"Entrenando el modelo...\")\n",
    "model_220617_bag.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "model_220617_bag.fit(tf.constant(x_train_220617_bag), tf.cast(tf.constant(y_train_220617_bag), tf.float64), epochs=10, callbacks=cp_220617_bag, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 27ms/step - loss: 20.4949 - accuracy: 0.7308\n"
     ]
    }
   ],
   "source": [
    "evals = model_220617_bag.evaluate(tf.constant(x_test_220617_bag), tf.cast(tf.constant(y_test_220617_bag), tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmonedero/TFG/tfg_env/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_220617_bag.save('MHAMemo/mha.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
