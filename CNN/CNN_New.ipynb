{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 09:26:02.425450: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-11 09:26:02.475759: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-11 09:26:02.475784: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-11 09:26:02.477208: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-11 09:26:02.485483: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-11 09:26:03.569613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import DataFunctions as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo datos...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hecho!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Se obtienen los datos de los sensores y las etiquetas deducidas\n",
    "print(\"Obteniendo datos...\")\n",
    "data_2206_17_bag, tags_220617_bag = data.get_data('/home/cmonedero/TFG/User1/Motion/User1_220617_Bag.csv', '/home/cmonedero/TFG/User1/220617/Label_New_User1_220617.txt')\n",
    "# print(\"Tamaño ventanas X --> \", x_windows_220617_bag.shape)\n",
    "# print(\"Tamaño ventanas Y --> \", y_windows_220617_bag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hecho!\n",
      "\n",
      "(3651, 500, 6)\n",
      "(3651,)\n"
     ]
    }
   ],
   "source": [
    "x_windows_220617_bag, y_windows_220617_bag = data.divide_data_arrays_into_windows(data_2206_17_bag, tags_220617_bag, window_size=500, moda=True)\n",
    "x_train_220617_bag, y_train_220617_bag, x_test_220617_bag, y_test_220617_bag = data.divide_train_test(x_windows_220617_bag, y_windows_220617_bag, 0.7)\n",
    "print(x_windows_220617_bag.shape)\n",
    "print(y_windows_220617_bag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 5 6]\n",
      "[2 3 5]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train_220617_bag))\n",
    "print(np.unique(y_test_220617_bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape input (None, 500, 6)\n",
      "Shape conv1D (None, 491, 64)\n",
      "Shape segunda conv1D (None, 482, 64)\n",
      "Shape despues de Max Pooling (None, 241, 64)\n",
      "Shape tercera conv1D (None, 232, 64)\n",
      "Shape cuarta conv1D (None, 223, 64)\n",
      "Shape despues del global avg pooling (None, 64)\n",
      "Shape despues Flatten (None, 64)\n",
      "Output shape (None, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 16:08:25.579337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 970 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:31:00.0, compute capability: 8.6\n",
      "2024-05-15 16:08:25.581048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 40933 MB memory:  -> device: 1, name: NVIDIA A40, pci bus id: 0000:98:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(500,6))\n",
    "x = inputs\n",
    "print(f'Shape input {inputs.shape}')\n",
    "x = Conv1D(filters=64, kernel_size=10, data_format='channels_last')(x)\n",
    "print(f'Shape conv1D {x.shape}')\n",
    "x = Conv1D(filters=64, kernel_size=10, data_format='channels_last')(x)\n",
    "print(f'Shape segunda conv1D {x.shape}')\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "print(f'Shape despues de Max Pooling {x.shape}')\n",
    "x = Conv1D(filters=64, kernel_size=10, data_format='channels_last')(x)\n",
    "print(f'Shape tercera conv1D {x.shape}')\n",
    "x = Conv1D(filters=64, kernel_size=10, data_format='channels_last')(x)\n",
    "print(f'Shape cuarta conv1D {x.shape}')\n",
    "x = GlobalAveragePooling1D(data_format='channels_last')(x)\n",
    "print(f'Shape despues del global avg pooling {x.shape}')\n",
    "x = Flatten()(x)\n",
    "print(f'Shape despues Flatten {x.shape}')\n",
    "outputs = Dense(8, activation='softmax')(x)\n",
    "print(f'Output shape {outputs.shape}')\n",
    "\n",
    "modelo = keras.Model(inputs, outputs)\n",
    "\n",
    "modelo.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 500, 6)]          0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 491, 64)           3904      \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 482, 64)           41024     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 241, 64)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 232, 64)           41024     \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 223, 64)           41024     \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 64)                0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 127496 (498.03 KB)\n",
      "Trainable params: 127496 (498.03 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(modelo.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 16:08:34.641435: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-05-15 16:08:34.766839: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-05-15 16:08:35.138093: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f950d296410 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-15 16:08:35.138159: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6\n",
      "2024-05-15 16:08:35.138172: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA A40, Compute Capability 8.6\n",
      "2024-05-15 16:08:35.157204: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-15 16:08:35.267937: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715789315.352642  975591 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-05-15 16:08:35.795637: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-05-15 16:08:35.816055: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-05-15 16:08:36.113393: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-05-15 16:08:36.132113: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/80 [===========================>..] - ETA: 0s - loss: 5.0850 - accuracy: 0.5839"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 16:08:37.927937: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-05-15 16:08:37.945675: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-05-15 16:08:38.013246: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-05-15 16:08:38.030860: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 5s 18ms/step - loss: 4.8613 - accuracy: 0.5969\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3364 - accuracy: 0.8912\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3425 - accuracy: 0.8857\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.4921 - accuracy: 0.8250\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3317 - accuracy: 0.8806\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3073 - accuracy: 0.8885\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3039 - accuracy: 0.8900\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3178 - accuracy: 0.8748\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3110 - accuracy: 0.8904\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3418 - accuracy: 0.8939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9a67a734c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(tf.constant(x_train_220617_bag), tf.cast(tf.constant(y_train_220617_bag), tf.float32), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/35 [..............................] - ETA: 1s - loss: 2.0839e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 5ms/step - loss: 16.6081 - accuracy: 0.6916\n"
     ]
    }
   ],
   "source": [
    "evals = modelo.evaluate(tf.constant(x_test_220617_bag), tf.cast(tf.constant(y_test_220617_bag), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.save('CNNMemo/cnn.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
